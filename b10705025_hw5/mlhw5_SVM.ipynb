{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q00JF9knfdhg",
        "outputId": "982d2e34-ac29-498e-c032-912b43a9e190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sCTQXp9kTcm8_jckqC-v_gWxIsFCcUbS\n",
            "To: /content/X_train\n",
            "100% 7.14M/7.14M [00:00<00:00, 41.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vK24A09o5Nev5qj1qNhndFe6beTWSDRU\n",
            "To: /content/Y_train\n",
            "100% 65.1k/65.1k [00:00<00:00, 42.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1THvOuf_EOn6c_6TLy0Bqs23BP2NraBR2\n",
            "To: /content/X_test\n",
            "100% 3.57M/3.57M [00:00<00:00, 78.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1sCTQXp9kTcm8_jckqC-v_gWxIsFCcUbS\n",
        "!gdown 1vK24A09o5Nev5qj1qNhndFe6beTWSDRU\n",
        "!gdown 1THvOuf_EOn6c_6TLy0Bqs23BP2NraBR2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-i7a0zITdd0h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "14_RdKtHfu1j"
      },
      "outputs": [],
      "source": [
        "def normalize(X, mu_x=None, std_x=None):\n",
        "\n",
        "  #ToDo Begin\n",
        "\n",
        "  if mu_x is None and std_x is None:\n",
        "    mu_x = np.mean(X, axis=0)\n",
        "    std_x = np.std(X, axis=0)\n",
        "\n",
        "  #ToDo End\n",
        "  X = (X - mu_x) / std_x\n",
        "  return X, mu_x, std_x\n",
        "\n",
        "def load_train():\n",
        "  X = pd.read_csv(\"X_train\")\n",
        "  X_c = X[['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']].values\n",
        "  X_d = X.drop(['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss'], 1).iloc[:, :-1].values\n",
        "  Y = pd.read_csv(\"Y_train\", header = None).values.reshape(-1)\n",
        "  X_c, mu, std = normalize(X_c)\n",
        "  X = np.concatenate((X_d, X_c), 1)\n",
        "  return X, Y, mu, std\n",
        "\n",
        "def load_test(mu, std):\n",
        "  X = pd.read_csv(\"X_test\")\n",
        "  X_c = X[['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss']].values\n",
        "  X_d = X.drop(['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss'], 1).iloc[:, :-1].values\n",
        "  X_c, a, b = normalize(X_c, mu, std)\n",
        "  X = np.concatenate((X_d, X_c), 1)\n",
        "  return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvWtcFbzgCG4",
        "outputId": "0d94dea6-48b8-464b-e687-585922237617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-c198a1067f96>:16: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  X_d = X.drop(['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss'], 1).iloc[:, :-1].values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.85816468e+01 1.89778367e+05 4.04374559e+01 1.07764884e+03\n",
            " 8.73038297e+01]\n",
            "[1.36402231e+01 1.05548357e+05 1.23472391e+01 7.38517868e+03\n",
            " 4.02954031e+02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-c198a1067f96>:25: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  X_d = X.drop(['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss'], 1).iloc[:, :-1].values\n"
          ]
        }
      ],
      "source": [
        "train_X, train_Y, mu, std = load_train()\n",
        "print(mu)\n",
        "print(std)\n",
        "test_X = load_test(mu, std)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_X.shape)\n",
        "print(train_X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnpEAITFMpFB",
        "outputId": "bd78a053-5987-4b08-a935-615ec848e358"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16281, 105)\n",
            "(32561, 105)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RNTx_SOIk53U"
      },
      "outputs": [],
      "source": [
        "#ToDo Begin\n",
        "pca = PCA(n_components=16)#think what number should set\n",
        "pca.fit(train_X)\n",
        "train_X1 = pca.transform(train_X)\n",
        "\n",
        "\n",
        "#ToDo End\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-QsqxscNnkS",
        "outputId": "8891f1e6-7524-4ee7-c3e1-f4e1f7088a48"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32561, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf=SVC(kernel='rbf',C=1,gamma='auto')\n",
        "clf.fit(train_X1, train_Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "wJ6OYT5YM-Pu",
        "outputId": "057e0418-4d9e-4561-c47b-0218c6ca8d61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, gamma='auto')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LS6LHG3bntKv"
      },
      "outputs": [],
      "source": [
        "test_X1 = pca.transform(test_X)\n",
        "results = clf.predict(test_X1)\n",
        "with open('predict.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['id','label'])\n",
        "    for i, x in enumerate(results):\n",
        "      writer.writerow([i + 1, int(x)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Doing linear kernal for feature transformation output dim = 4\n"
      ],
      "metadata": {
        "id": "iBoW49oBw0aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FeatureTransformer(nn.Module):\n",
        "    def __init__(self,output_dim, input_dim = 105 , hidden_dim = 20 ):\n",
        "        super(FeatureTransformer, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "xVK6L7ULuT_O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim = 4\n",
        "transformer = FeatureTransformer(output_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001)\n",
        "num_epochs = 500\n",
        "tensor_X = torch.tensor(train_X).float()\n",
        "pca1 = PCA(n_components=4)#think what number should set\n",
        "pca1.fit(train_X)\n",
        "train_X1 = pca1.transform(train_X)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    output = transformer(tensor_X)\n",
        "    loss = criterion(output, torch.tensor(train_X1).float())  # Using MSE loss for demonstration\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if(epoch % 100) == 0:\n",
        "      print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh3yBTSZuef1",
        "outputId": "fdc95dfd-6068-414a-fa78-0ea8fe06bea8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500], Loss: 1.1393\n",
            "Epoch [101/500], Loss: 0.3192\n",
            "Epoch [201/500], Loss: 0.0140\n",
            "Epoch [301/500], Loss: 0.0028\n",
            "Epoch [401/500], Loss: 0.0016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_x = transformer(torch.tensor(train_X).float())\n",
        "new_test = transformer(torch.tensor(test_X).float())"
      ],
      "metadata": {
        "id": "SDuB7mAMx2KV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_x = new_x.detach().numpy()\n",
        "new_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtfoB5dazbRo",
        "outputId": "1d28d1e7-ea82-4e73-8a31-81e92029591b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32561, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_new=SVC(kernel='linear', C=1)\n",
        "clf_new.fit(new_x, train_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "5ziKrd-ayYbY",
        "outputId": "f1c11130-8f23-424c-eacf-06e8043ab41f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_test = new_test.detach().numpy()\n",
        "new_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1XR5HgjztqZ",
        "outputId": "4ed93eff-0f25-4237-a63e-e659d52df19a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16281, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_new = clf_new.predict(new_test)\n",
        "with open('predict for output = 4.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['id','label'])\n",
        "    for i, x in enumerate(results_new):\n",
        "      writer.writerow([i + 1, int(x)])"
      ],
      "metadata": {
        "id": "VP_y2Djwz6aU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Doing linear kernal for feature transformation output dim = 1024\n",
        "\n"
      ],
      "metadata": {
        "id": "w3JVtKoa0lpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim = 1024\n",
        "transformer_1024 = FeatureTransformer(output_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(transformer_1024.parameters(), lr=0.001)\n",
        "num_epochs = 500\n",
        "np.random.seed(42)\n",
        "train_x1 = np.random.rand(32561, 1024)\n",
        "train_x1[:, :105] = train_X\n",
        "tensor_X_1024 = torch.tensor(train_X).float()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    output = transformer_1024(tensor_X_1024)\n",
        "    loss = criterion(output, torch.tensor(train_x1).float())  # Using MSE loss for demonstration\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if(epoch % 100) == 0:\n",
        "      print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-doONeQ20eqA",
        "outputId": "fd9d4990-5060-4bbf-d728-dd702c2c4dc6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500], Loss: 0.3332\n",
            "Epoch [101/500], Loss: 0.0875\n",
            "Epoch [201/500], Loss: 0.0837\n",
            "Epoch [301/500], Loss: 0.0825\n",
            "Epoch [401/500], Loss: 0.0815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_x = transformer_1024(torch.tensor(train_X).float())\n",
        "new_test = transformer_1024(torch.tensor(test_X).float())\n",
        "new_x = new_x.detach().numpy()\n",
        "new_test = new_test.detach().numpy()\n",
        "new_x.shape, new_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T55OyX3J3Fbp",
        "outputId": "c0d149c9-0a58-47b5-c76f-2adeff5c9762"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32561, 1024), (16281, 1024))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_new_1024=SVC(kernel='linear', C=1)\n",
        "clf_new_1024.fit(new_x, train_Y)"
      ],
      "metadata": {
        "id": "TsfiiQCS3cBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_new_1024 = clf_new_1024.predict(new_test)\n",
        "with open('predict for output = 1024.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['id','label'])\n",
        "    for i, x in enumerate(results_new_1024):\n",
        "      writer.writerow([i + 1, int(x)])"
      ],
      "metadata": {
        "id": "vfb7BxW43lKb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}